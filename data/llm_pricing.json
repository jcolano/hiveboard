[
  {
    "model_pattern": "claude-opus-4",
    "provider": "anthropic",
    "input_per_m": 15.0,
    "output_per_m": 75.0
  },
  {
    "model_pattern": "claude-sonnet-4",
    "provider": "anthropic",
    "input_per_m": 3.0,
    "output_per_m": 15.0
  },
  {
    "model_pattern": "claude-3-7-sonnet",
    "provider": "anthropic",
    "input_per_m": 3.0,
    "output_per_m": 15.0
  },
  {
    "model_pattern": "claude-3-5-sonnet",
    "provider": "anthropic",
    "input_per_m": 3.0,
    "output_per_m": 15.0
  },
  {
    "model_pattern": "claude-3-5-haiku",
    "provider": "anthropic",
    "input_per_m": 0.8,
    "output_per_m": 4.0
  },
  {
    "model_pattern": "claude-3-opus",
    "provider": "anthropic",
    "input_per_m": 15.0,
    "output_per_m": 75.0
  },
  {
    "model_pattern": "claude-3-haiku",
    "provider": "anthropic",
    "input_per_m": 0.25,
    "output_per_m": 1.25
  },
  {
    "model_pattern": "claude-sonnet-4-5",
    "provider": "anthropic",
    "input_per_m": 3.0,
    "output_per_m": 15.0
  },
  {
    "model_pattern": "claude-haiku-4-5",
    "provider": "anthropic",
    "input_per_m": 0.8,
    "output_per_m": 4.0
  },
  {
    "model_pattern": "gpt-4o",
    "provider": "openai",
    "input_per_m": 2.5,
    "output_per_m": 10.0
  },
  {
    "model_pattern": "gpt-4o-mini",
    "provider": "openai",
    "input_per_m": 0.15,
    "output_per_m": 0.6
  },
  {
    "model_pattern": "gpt-4-turbo",
    "provider": "openai",
    "input_per_m": 10.0,
    "output_per_m": 30.0
  },
  {
    "model_pattern": "gpt-4",
    "provider": "openai",
    "input_per_m": 30.0,
    "output_per_m": 60.0
  },
  {
    "model_pattern": "o1",
    "provider": "openai",
    "input_per_m": 15.0,
    "output_per_m": 60.0
  },
  {
    "model_pattern": "o3-mini",
    "provider": "openai",
    "input_per_m": 1.1,
    "output_per_m": 4.4
  },
  {
    "model_pattern": "gemini-2.0-flash",
    "provider": "google",
    "input_per_m": 0.1,
    "output_per_m": 0.4
  },
  {
    "model_pattern": "gemini-1.5-pro",
    "provider": "google",
    "input_per_m": 1.25,
    "output_per_m": 5.0
  },
  {
    "model_pattern": "gemini-1.5-flash",
    "provider": "google",
    "input_per_m": 0.075,
    "output_per_m": 0.3
  },
  {
    "model_pattern": "mistral-large",
    "provider": "mistral",
    "input_per_m": 2.0,
    "output_per_m": 6.0
  },
  {
    "model_pattern": "mistral-small",
    "provider": "mistral",
    "input_per_m": 0.2,
    "output_per_m": 0.6
  },
  {
    "model_pattern": "codestral",
    "provider": "mistral",
    "input_per_m": 0.3,
    "output_per_m": 0.9
  },
  {
    "model_pattern": "llama-3.1-405b",
    "provider": "meta",
    "input_per_m": 3.0,
    "output_per_m": 3.0
  },
  {
    "model_pattern": "llama-3.1-70b",
    "provider": "meta",
    "input_per_m": 0.9,
    "output_per_m": 0.9
  },
  {
    "model_pattern": "llama-3.1-8b",
    "provider": "meta",
    "input_per_m": 0.1,
    "output_per_m": 0.1
  }
]